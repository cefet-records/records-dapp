# üéì Academic Record Management DApp

**T√≠tulo do TCC:** Aplica√ß√£o de Tecnologias Descentralizadas para Gest√£o de Registros Acad√™micos e Transfer√™ncia de Cr√©ditos
**Alunos:**
* Gabriel Franco Barreto Cavalcanti
* Gilmar Santos Neto
* Juan Carvalho Silva de Lima
**Semestre de Defesa:** 2025-2

[PDF do TCC](./public/tcc.pdf)

# TL;DR

Este projeto √© composto por tr√™s m√≥dulos independentes que trabalham de forma integrada. Certifique-se de clonar todos para a execu√ß√£o completa:

* üñ•Ô∏è **DApp (Este reposit√≥rio):** Interface Web3 para usu√°rios e institui√ß√µes.
* üìú **[Smart Contracts](https://github.com/cefet-records/records-smart-contract):** Contratos inteligentes em Solidity e ambiente de desenvolvimento Hardhat.
* ‚öôÔ∏è **[Records Batch](https://github.com/cefet-records/records-batch):** Pipeline de dados e orquestra√ß√£o de processos em lote com Apache Airflow.

---

## üõ†Ô∏è Pr√©-requisitos

Antes de iniciar, certifique-se de possuir:

* [Node.js](https://nodejs.org/) (v18+)
* [Docker & Docker Compose](https://www.docker.com/)
* Conta ativa na [Dynamic.xyz](https://www.dynamic.xyz/)
* [Ngrok](https://ngrok.com/) instalado

---

## üì¶ Guia de Instala√ß√£o e Execu√ß√£o

### 1. Smart Contracts ([Acessar Repo](https://github.com/cefet-records/records-smart-contract))

Abra o reposit√≥rio dos contratos e inicie o n√≥ local:

```bash
cd records-smart-contract
npm install
npx hardhat node

```

Em um novo terminal, realize o deploy:

```bash
npx hardhat ignition deploy ./ignition/modules/AcademicRecordStorage.ts --network localhost

```

### 2. DApp (Interface Frontend)

Neste reposit√≥rio, instale as depend√™ncias e inicie o servidor:

```bash
npm install
npm run dev

```

**Conex√£o com Dynamic (MPC):** √â obrigat√≥rio expor a porta local para permitir a integra√ß√£o com as chaves de seguran√ßa da Dynamic:

```bash
npx ngrok http 3000

```

> ‚ö†Ô∏è **Aten√ß√£o:** √â necess√°rio configurar o dom√≠nio gerado pelo ngrok no painel administrativo da Dynamic para habilitar as carteiras embarcadas.

### 3. Records Batch ([Acessar Repo](https://github.com/cefet-records/records-batch))

Abra o reposit√≥rio de orquestra√ß√£o e inicie os containers:

```bash
cd records-batch
docker-compose up -d

```

Acesse o painel em `localhost:8080` para gerenciar os disparos via CSV.

---

# Descri√ß√£o Geral

Sistema descentralizado para gest√£o de registros acad√™micos com foco em **escalabilidade**, **privacidade** e **baixas taxas de transa√ß√£o**. O projeto utiliza orquestra√ß√£o de dados em lote e carteiras embarcadas para uma experi√™ncia de usu√°rio simplificada.

# Funcionalidades

* **Gest√£o Institucional de Registos em Lote**
  * Ingest√£o automatizada de grandes volumes de dados de estudantes, cursos e disciplinas.
  * Processamento de notas de forma coletiva para redu√ß√£o dr√°stica de custos de rede.
  * Valida√ß√£o de integridade e unicidade dos dados antes da persist√™ncia na blockchain.
* **Privacidade e Prote√ß√£o de Dados Sens√≠veis**
  * Cifragem de ponta a ponta (*client-side*) utilizando o esquema ECIES.
  * Prote√ß√£o da identidade do estudante (nome e documentos) fora da rede p√∫blica.
  * Implementa√ß√£o de motor criptogr√°fico local com AES-256-GCM e PBKDF2.
* **Soberania de Identidade e Carteira Embarcada**
  * Integra√ß√£o com *Embedded Wallets* (Dynamic MPC) para abstra√ß√£o da complexidade Web3.
  * Gest√£o de chaves privadas baseada em Senha Mestra de conhecimento exclusivo do titular.
  * Independ√™ncia de extens√µes de navegador ou bibliotecas de carteiras legadas.
* **Controlo de Acesso Condicional**
  * Fluxo descentralizado para solicita√ß√£o de acesso por visitantes externos.
  * Mecanismo de recifragem direcionada para partilha segura de hist√≥ricos acad√™micos.
  * Trilha de auditoria imut√°vel de todas as concess√µes de acesso realizadas.
* **Otimiza√ß√£o de Custos e Escalabilidade**
  * Agrega√ß√£o de transa√ß√µes (*batching*) para dilui√ß√£o das taxas de *gas*.
  * Compatibilidade com redes EVM de camada 2 (Polygon) para viabilidade econ√≥mica.
  * Orquestra√ß√£o de pipelines de dados via Apache Airflow integrada ao DApp.

